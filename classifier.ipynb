{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 02:03:21.416165: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-07 02:03:22.181806: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-07 02:03:22.181863: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-11-07 02:03:22.264057: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-11-07 02:03:23.766627: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-07 02:03:23.766777: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2022-11-07 02:03:23.766785: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras_preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10288 images belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "train_data = train_datagen.flow_from_directory('./dataset_model/train/',target_size = (64,64),batch_size=256,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1808 images belonging to 21 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_data = test_datagen.flow_from_directory('./dataset_model/test/',target_size=(64,64),batch_size = 256,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-07 02:03:26.345958: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-11-07 02:03:26.346709: W tensorflow/stream_executor/cuda/cuda_driver.cc:263] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-11-07 02:03:26.346739: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (keshav-Mi-NoteBook): /proc/driver/nvidia/version does not exist\n",
      "2022-11-07 02:03:26.347576: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters = 96,kernel_size=5,strides=3,padding = 'same',activation = 'relu',input_shape=[64,64,3]))\n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=3,strides = 2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 384,kernel_size=3,strides=1,padding = 'same',activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 384,kernel_size=3,strides=1,padding = 'same',activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.Conv2D(filters = 256,kernel_size=3,strides=1,padding = 'same',activation = 'relu'))\n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=3,strides = 2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=1024,activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dropout(0.5))\n",
    "cnn.add(tf.keras.layers.Dense(units=1024,activation='relu'))\n",
    "cnn.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=21,activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer = 'adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 22, 22, 96)        7296      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 10, 10, 96)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 10, 10, 384)       332160    \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 10, 10, 384)       1327488   \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 10, 10, 256)       884992    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 4, 4, 256)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              4195328   \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 21)                21525     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,818,389\n",
      "Trainable params: 7,818,389\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "cnn = keras.models.load_model('./1_10.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "41/41 [==============================] - 167s 4s/step - loss: 0.7065 - accuracy: 0.7576 - val_loss: 0.7308 - val_accuracy: 0.7600\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 166s 4s/step - loss: 0.6325 - accuracy: 0.7844 - val_loss: 0.6523 - val_accuracy: 0.7848\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 165s 4s/step - loss: 0.5510 - accuracy: 0.8166 - val_loss: 0.6285 - val_accuracy: 0.7898\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 166s 4s/step - loss: 0.5037 - accuracy: 0.8325 - val_loss: 0.5529 - val_accuracy: 0.8191\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 165s 4s/step - loss: 0.4575 - accuracy: 0.8479 - val_loss: 0.5340 - val_accuracy: 0.8335\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 167s 4s/step - loss: 0.4101 - accuracy: 0.8629 - val_loss: 0.5380 - val_accuracy: 0.8291\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 166s 4s/step - loss: 0.3973 - accuracy: 0.8663 - val_loss: 0.4999 - val_accuracy: 0.8429\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 167s 4s/step - loss: 0.3145 - accuracy: 0.8941 - val_loss: 0.4471 - val_accuracy: 0.8584\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 169s 4s/step - loss: 0.2923 - accuracy: 0.8998 - val_loss: 0.4768 - val_accuracy: 0.8534\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 171s 4s/step - loss: 0.2142 - accuracy: 0.9273 - val_loss: 0.4846 - val_accuracy: 0.8573\n",
      "Epoch 1/10\n",
      "41/41 [==============================] - 169s 4s/step - loss: 0.2109 - accuracy: 0.9290 - val_loss: 0.5499 - val_accuracy: 0.8418\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 171s 4s/step - loss: 0.2046 - accuracy: 0.9313 - val_loss: 0.5498 - val_accuracy: 0.8457\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 170s 4s/step - loss: 0.1640 - accuracy: 0.9432 - val_loss: 0.5725 - val_accuracy: 0.8595\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 170s 4s/step - loss: 0.1463 - accuracy: 0.9507 - val_loss: 0.5367 - val_accuracy: 0.8612\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 171s 4s/step - loss: 0.1599 - accuracy: 0.9460 - val_loss: 0.6490 - val_accuracy: 0.8263\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 169s 4s/step - loss: 0.1991 - accuracy: 0.9338 - val_loss: 0.5621 - val_accuracy: 0.8617\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 170s 4s/step - loss: 0.1342 - accuracy: 0.9550 - val_loss: 0.5973 - val_accuracy: 0.8440\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 170s 4s/step - loss: 0.0877 - accuracy: 0.9713 - val_loss: 0.6118 - val_accuracy: 0.8479\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 170s 4s/step - loss: 0.0837 - accuracy: 0.9717 - val_loss: 0.5589 - val_accuracy: 0.8612\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 170s 4s/step - loss: 0.0710 - accuracy: 0.9774 - val_loss: 0.6173 - val_accuracy: 0.8579\n",
      "Epoch 1/10\n",
      "41/41 [==============================] - 170s 4s/step - loss: 0.0718 - accuracy: 0.9770 - val_loss: 0.5863 - val_accuracy: 0.8584\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 170s 4s/step - loss: 0.0634 - accuracy: 0.9791 - val_loss: 0.7069 - val_accuracy: 0.8451\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 168s 4s/step - loss: 0.0846 - accuracy: 0.9721 - val_loss: 0.6216 - val_accuracy: 0.8590\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 168s 4s/step - loss: 0.1014 - accuracy: 0.9655 - val_loss: 0.8040 - val_accuracy: 0.8114\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 168s 4s/step - loss: 0.1098 - accuracy: 0.9642 - val_loss: 0.5972 - val_accuracy: 0.8562\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 168s 4s/step - loss: 0.0625 - accuracy: 0.9797 - val_loss: 0.6404 - val_accuracy: 0.8579\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 167s 4s/step - loss: 0.0505 - accuracy: 0.9843 - val_loss: 0.6395 - val_accuracy: 0.8739\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 169s 4s/step - loss: 0.0361 - accuracy: 0.9892 - val_loss: 0.6645 - val_accuracy: 0.8733\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 167s 4s/step - loss: 0.0765 - accuracy: 0.9752 - val_loss: 0.5923 - val_accuracy: 0.8545\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 170s 4s/step - loss: 0.0547 - accuracy: 0.9822 - val_loss: 0.6319 - val_accuracy: 0.8590\n",
      "Epoch 1/10\n",
      "41/41 [==============================] - 167s 4s/step - loss: 0.0335 - accuracy: 0.9885 - val_loss: 0.7879 - val_accuracy: 0.8529\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 165s 4s/step - loss: 0.0433 - accuracy: 0.9854 - val_loss: 0.6942 - val_accuracy: 0.8562\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 169s 4s/step - loss: 0.0384 - accuracy: 0.9877 - val_loss: 0.7058 - val_accuracy: 0.8573\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 169s 4s/step - loss: 0.0493 - accuracy: 0.9837 - val_loss: 0.7189 - val_accuracy: 0.8573\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 166s 4s/step - loss: 0.0766 - accuracy: 0.9762 - val_loss: 0.7284 - val_accuracy: 0.8556\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 166s 4s/step - loss: 0.0391 - accuracy: 0.9878 - val_loss: 0.6885 - val_accuracy: 0.8634\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 168s 4s/step - loss: 0.0229 - accuracy: 0.9934 - val_loss: 0.6750 - val_accuracy: 0.8684\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 168s 4s/step - loss: 0.0242 - accuracy: 0.9931 - val_loss: 0.8504 - val_accuracy: 0.8573\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 168s 4s/step - loss: 0.0467 - accuracy: 0.9840 - val_loss: 0.6471 - val_accuracy: 0.8662\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 168s 4s/step - loss: 0.0618 - accuracy: 0.9806 - val_loss: 0.7214 - val_accuracy: 0.8584\n",
      "Epoch 1/10\n",
      "41/41 [==============================] - 168s 4s/step - loss: 0.0773 - accuracy: 0.9747 - val_loss: 0.7000 - val_accuracy: 0.8451\n",
      "Epoch 2/10\n",
      "41/41 [==============================] - 168s 4s/step - loss: 0.0645 - accuracy: 0.9806 - val_loss: 0.7870 - val_accuracy: 0.8357\n",
      "Epoch 3/10\n",
      "41/41 [==============================] - 168s 4s/step - loss: 0.0534 - accuracy: 0.9824 - val_loss: 0.7419 - val_accuracy: 0.8579\n",
      "Epoch 4/10\n",
      "41/41 [==============================] - 166s 4s/step - loss: 0.0258 - accuracy: 0.9921 - val_loss: 0.7663 - val_accuracy: 0.8573\n",
      "Epoch 5/10\n",
      "41/41 [==============================] - 169s 4s/step - loss: 0.0248 - accuracy: 0.9924 - val_loss: 0.6591 - val_accuracy: 0.8717\n",
      "Epoch 6/10\n",
      "41/41 [==============================] - 166s 4s/step - loss: 0.0208 - accuracy: 0.9934 - val_loss: 0.7810 - val_accuracy: 0.8523\n",
      "Epoch 7/10\n",
      "41/41 [==============================] - 169s 4s/step - loss: 0.0418 - accuracy: 0.9879 - val_loss: 0.6619 - val_accuracy: 0.8678\n",
      "Epoch 8/10\n",
      "41/41 [==============================] - 168s 4s/step - loss: 0.0162 - accuracy: 0.9942 - val_loss: 0.6953 - val_accuracy: 0.8767\n",
      "Epoch 9/10\n",
      "41/41 [==============================] - 168s 4s/step - loss: 0.0148 - accuracy: 0.9961 - val_loss: 0.8328 - val_accuracy: 0.8567\n",
      "Epoch 10/10\n",
      "41/41 [==============================] - 169s 4s/step - loss: 0.0184 - accuracy: 0.9935 - val_loss: 0.8923 - val_accuracy: 0.8579\n"
     ]
    }
   ],
   "source": [
    "for i in range(6):          #save after every 10 iterations total 60 iterations\n",
    "    cnn.fit(x=train_data,validation_data=test_data,epochs = 10)\n",
    "    cnn.save('1_'+str((i+2)*10)+'.h5')\n",
    "cnn.save('final.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
